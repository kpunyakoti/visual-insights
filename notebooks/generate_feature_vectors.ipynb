{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293bd6d2-e400-45f1-bd47-522943045277",
   "metadata": {},
   "source": [
    "## Generate Feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf003b0e-8b65-4dc8-b962-2d9b28875954",
   "metadata": {},
   "source": [
    "In this notebook we generate feature vectors for each image and store them in sqlite database. These feature vectors are easy to store and retrieve providing an easy access to do further computations on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac109eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sange\\.conda\\envs\\vi\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import cv2\n",
    "import sqlite3 as db\n",
    "import array\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e96809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x21dea293110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the feature database (or create one if it doesn't exist)\n",
    "conn = db.connect('featureDB.db')\n",
    "# Create a 'cursor' for executing commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create a table named \"ImageFeatures\"  if it doesnt exist\n",
    "cursor.execute(\"CREATE TABLE IF NOT EXISTS ImageFeatures (iID TEXT, fV BLOB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c996f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageArrayFromFile(img_path):\n",
    "    img       = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a76e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeatureVector(img_path, model):\n",
    "    img_array = getImageArrayFromFile(img_path)\n",
    "    feature_vector = model.predict(img_array)\n",
    "    return feature_vector.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be58d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_feature_vector(image_ID, feature_vector):\n",
    "    # Convert th feature vector as bytes and store it into the database\n",
    "    fv_bytes = feature_vector.tobytes()\n",
    "    cursor.execute(\"INSERT INTO ImageFeatures (iID, fV)  VALUES (?, ?)\",(image_ID,fv_bytes))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c741348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_feature_vector(image_ID):\n",
    "    #Get the row\n",
    "    query = \"SELECT * FROM ImageFeatures WHERE iID = '\" + image_ID + \"'\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "\n",
    "    if result is not None:\n",
    "        # Convert the bytes back to a float array and return it\n",
    "        float_array_bytes = result[1]\n",
    "        float_array = np.frombuffer(float_array_bytes, dtype='float32')\n",
    "        return float_array\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6203a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fv_inDB(image_ID):  \n",
    "    # Retrieve the record from the database\n",
    "    query = \"SELECT * FROM ImageFeatures WHERE iID = '\" + image_ID + \"'\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    #If there is no result then return false\n",
    "    if result is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83e2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFV_ImagesInFolder (folderPath, model):\n",
    "    #For each of the image in the directory\n",
    "    for img in tqdm.tqdm(os.listdir(folderPath)):\n",
    "        img_path = os.path.join(folderPath, img) \n",
    "        \n",
    "        #If the image was not analysed before, compute the feature vector and update in DB\n",
    "        if(not check_fv_inDB(img)):\n",
    "            fv = computeFeatureVector(img_path, model)\n",
    "            store_feature_vector(img, fv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e7d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is not used any more!\n",
    "def find_similar_images(query_image_path, image_directory, model, top_n=30):\n",
    "    query_vector = computeFeatureVector(query_image_path, model)\n",
    "\n",
    "    #image_paths = [os.path.join(image_directory, img) for img in os.listdir(image_directory)]\n",
    "    #image_paths = [os.path.join(image_directory, img) for img in os.listdir(image_directory)]\n",
    "    #image_vectors = [compute_feature_vector(img_path, model) for img_path in image_paths]\n",
    "    image_files = [img for img in os.listdir(image_directory)]\n",
    "    image_vectors = [compute_feature_vector(os.path.join(image_directory, img_file), model) for img_file in image_files]\n",
    "    \n",
    "    similarities = cosine_similarity([query_vector], image_vectors).flatten()\n",
    "    indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    similar_images_folder = 'D:\\projects\\dva\\simimages'\n",
    "\n",
    "    print(f\"\\nTop {top_n} similar images to '{query_image_path}':\")\n",
    "    for i in range(top_n):\n",
    "        print(f\"{i + 1}. {image_paths[indices[i]]} (Similarity: {similarities[indices[i]]:.4f})\")\n",
    "        #Copy the file to the folder\n",
    "        shutil.copy2(image_paths[indices[i]], similar_images_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84014c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarityscore(image_id, fv_query):\n",
    "    fv_image = retrieve_feature_vector(image_id)\n",
    "    score = cosine_similarity([fv_image],[fv_query]).flatten()[0]\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2a282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_similar_images(query_image_path, image_directory, similar_images_folder, model):\n",
    "    #Find the feature vector of the query image\n",
    "    fv_query = computeFeatureVector(query_image_path, model)\n",
    "  \n",
    "    #Drop the similarity table if it already exists\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS sim_table\")\n",
    "    \n",
    "    # create the similaritytable\n",
    "    create_simtable_query = '''\n",
    "                            CREATE TABLE IF NOT EXISTS sim_table (\n",
    "                                id TEXT PRIMARY KEY,\n",
    "                                score INTEGER)\n",
    "                            '''\n",
    "    print(\"Computing similairty scores...\")\n",
    "    \n",
    "    # Execute the SQL command to create the similarity table\n",
    "    cursor.execute(create_simtable_query)\n",
    "   \n",
    "    #Get the list of image paths\n",
    "    cursor.execute('SELECT DISTINCT iID FROM ImageFeatures')\n",
    "    # Fetch the result\n",
    "    imageIDs = cursor.fetchall()\n",
    "    \n",
    "    # Define the SQL command to insert data into the similarity table\n",
    "    insert_data_simtable_query = '''\n",
    "                                INSERT INTO sim_table (id, score)\n",
    "                                VALUES (?, ?)\n",
    "                                '''\n",
    "    # Execute the SQL command to compute and insert data into similarity table\n",
    "    cursor.executemany(insert_data_simtable_query, [(iID[0], calculate_similarityscore(iID[0], fv_query)) for iID in imageIDs])\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    \n",
    "    # Query the top n similar images\n",
    "    query_similar_images = '''\n",
    "                            SELECT id FROM sim_table\n",
    "                            ORDER BY score DESC       \n",
    "                            LIMIT 30\n",
    "                            '''  \n",
    "    # Execute the SQL command\n",
    "    cursor.execute(query_similar_images)\n",
    "\n",
    "    # Fetch the result\n",
    "    top_rows = cursor.fetchall()\n",
    "\n",
    "    # Print the file name and copy the files to the folder\n",
    "    for row in top_rows:\n",
    "        print(row)\n",
    "        shutil.copy2(os.path.join(image_directory, row[0]), similar_images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8765e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing Images images in folder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:00<00:00, 22627.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n",
      "Computing similairty scores...\n",
      "Done.\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151603512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151604012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151604512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151605012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151605512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151606012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151606512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151607012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151607512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151608012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151608512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151609012404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151609512404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151609912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151610412404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151610912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151611412404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151611862404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151612362404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151612862404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151613362404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151613912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151614412404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151614912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151615412404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151615912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151616412404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151616912404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151617362404.jpg',)\n",
      "('n008-2018-08-01-15-16-36-0400__CAM_FRONT__1533151617912404.jpg',)\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(weights='imagenet')\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "\n",
    "    #Path to the directory with all the images\n",
    "    image_directory  = 'D:\\projects\\dva\\data\\samples\\CAM_FRONT'\n",
    "    # Path to the query image\n",
    "    query_image_path = 'D:\\projects\\dva\\data\\samples\\CAM_FRONT\\\\n015-2018-07-24-11-22-45+0800__CAM_FRONT__1532402936662460.jpg'\n",
    "    # Folder to store similar images\n",
    "    similar_images_folder = 'D:\\projects\\dva\\simimages'\n",
    "   \n",
    "    #Compute feature vectors for all the images in the folder\n",
    "    print(\"Analysing Images images in folder...\")\n",
    "    updateFV_ImagesInFolder(image_directory, model)\n",
    "    \n",
    "    # Find and store similar images\n",
    "    store_similar_images(query_image_path, image_directory, similar_images_folder, model)\n",
    "    \n",
    "    print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91c926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03552ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
